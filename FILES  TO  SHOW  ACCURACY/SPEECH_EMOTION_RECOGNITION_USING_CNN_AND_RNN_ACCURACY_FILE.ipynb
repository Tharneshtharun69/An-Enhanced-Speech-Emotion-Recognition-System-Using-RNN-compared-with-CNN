{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LVkl8h4CJHl",
        "outputId": "8478a35d-1397-4c0d-a436-382f9cb34764"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNRDbCz_BT1E",
        "outputId": "35810cee-c808-491d-aef8-0ff286685709"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.3432 - loss: 2.5229 - val_accuracy: 0.6387 - val_loss: 2.4217\n",
            "Epoch 2/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4169 - loss: 2.4390 - val_accuracy: 0.8487 - val_loss: 2.3405\n",
            "Epoch 3/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5720 - loss: 2.3443 - val_accuracy: 0.9076 - val_loss: 2.2627\n",
            "Epoch 4/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6714 - loss: 2.2739 - val_accuracy: 0.9328 - val_loss: 2.1879\n",
            "Epoch 5/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6929 - loss: 2.1968 - val_accuracy: 0.9412 - val_loss: 2.1127\n",
            "Epoch 6/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7404 - loss: 2.1342 - val_accuracy: 0.9496 - val_loss: 2.0372\n",
            "Epoch 7/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7940 - loss: 2.0532 - val_accuracy: 0.9496 - val_loss: 1.9624\n",
            "Epoch 8/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8408 - loss: 1.9740 - val_accuracy: 0.9496 - val_loss: 1.8879\n",
            "Epoch 9/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8276 - loss: 1.9284 - val_accuracy: 0.9496 - val_loss: 1.8163\n",
            "Epoch 10/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 1.8594 - val_accuracy: 0.9496 - val_loss: 1.7470\n",
            "Epoch 11/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9099 - loss: 1.7618 - val_accuracy: 0.9496 - val_loss: 1.6801\n",
            "Epoch 12/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8561 - loss: 1.7267 - val_accuracy: 0.9496 - val_loss: 1.6155\n",
            "Epoch 13/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9005 - loss: 1.6406 - val_accuracy: 0.9496 - val_loss: 1.5548\n",
            "Epoch 14/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 1.5628 - val_accuracy: 0.9496 - val_loss: 1.4977\n",
            "Epoch 15/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 1.5520 - val_accuracy: 0.9496 - val_loss: 1.4440\n",
            "Epoch 16/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 1.4907 - val_accuracy: 0.9496 - val_loss: 1.3947\n",
            "Epoch 17/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9219 - loss: 1.4551 - val_accuracy: 0.9496 - val_loss: 1.3492\n",
            "Epoch 18/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9148 - loss: 1.4132 - val_accuracy: 0.9496 - val_loss: 1.3069\n",
            "Epoch 19/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9385 - loss: 1.3637 - val_accuracy: 0.9496 - val_loss: 1.2661\n",
            "Epoch 20/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9223 - loss: 1.3297 - val_accuracy: 0.9496 - val_loss: 1.2291\n",
            "Epoch 21/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 1.3055 - val_accuracy: 0.9496 - val_loss: 1.1958\n",
            "Epoch 22/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9397 - loss: 1.2595 - val_accuracy: 0.9496 - val_loss: 1.1643\n",
            "Epoch 23/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9294 - loss: 1.2321 - val_accuracy: 0.9496 - val_loss: 1.1362\n",
            "Epoch 24/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9360 - loss: 1.2008 - val_accuracy: 0.9496 - val_loss: 1.1104\n",
            "Epoch 25/25\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9363 - loss: 1.1919 - val_accuracy: 0.9496 - val_loss: 1.0862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN model saved to disk.\n",
            "Epoch 1/35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 268ms/step - accuracy: 0.4552 - loss: 1.3690 - val_accuracy: 0.7479 - val_loss: 1.3403\n",
            "Epoch 2/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 198ms/step - accuracy: 0.7414 - loss: 1.3371 - val_accuracy: 0.8235 - val_loss: 1.3022\n",
            "Epoch 3/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.7743 - loss: 1.2992 - val_accuracy: 0.8067 - val_loss: 1.2568\n",
            "Epoch 4/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.7969 - loss: 1.2564 - val_accuracy: 0.8151 - val_loss: 1.1996\n",
            "Epoch 5/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.8006 - loss: 1.1969 - val_accuracy: 0.8067 - val_loss: 1.1251\n",
            "Epoch 6/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.7752 - loss: 1.1243 - val_accuracy: 0.7899 - val_loss: 1.0307\n",
            "Epoch 7/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 108ms/step - accuracy: 0.7629 - loss: 1.0253 - val_accuracy: 0.7731 - val_loss: 0.9185\n",
            "Epoch 8/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.7569 - loss: 0.9238 - val_accuracy: 0.7479 - val_loss: 0.7994\n",
            "Epoch 9/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.7290 - loss: 0.8136 - val_accuracy: 0.7647 - val_loss: 0.6948\n",
            "Epoch 10/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.7109 - loss: 0.7280 - val_accuracy: 0.7395 - val_loss: 0.6280\n",
            "Epoch 11/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 0.7008 - loss: 0.6709 - val_accuracy: 0.7479 - val_loss: 0.5858\n",
            "Epoch 12/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.7059 - loss: 0.6147 - val_accuracy: 0.7899 - val_loss: 0.5440\n",
            "Epoch 13/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.7560 - loss: 0.5811 - val_accuracy: 0.8151 - val_loss: 0.4996\n",
            "Epoch 14/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 190ms/step - accuracy: 0.8060 - loss: 0.5195 - val_accuracy: 0.8571 - val_loss: 0.4452\n",
            "Epoch 15/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.8454 - loss: 0.4557 - val_accuracy: 0.8908 - val_loss: 0.3823\n",
            "Epoch 16/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 181ms/step - accuracy: 0.8812 - loss: 0.3820 - val_accuracy: 0.9076 - val_loss: 0.3137\n",
            "Epoch 17/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9122 - loss: 0.3021 - val_accuracy: 0.9160 - val_loss: 0.2545\n",
            "Epoch 18/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9288 - loss: 0.2446 - val_accuracy: 0.9244 - val_loss: 0.2174\n",
            "Epoch 19/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9378 - loss: 0.2023 - val_accuracy: 0.9244 - val_loss: 0.1938\n",
            "Epoch 20/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 0.9391 - loss: 0.1762 - val_accuracy: 0.9412 - val_loss: 0.1804\n",
            "Epoch 21/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9564 - loss: 0.1484 - val_accuracy: 0.9496 - val_loss: 0.1688\n",
            "Epoch 22/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9538 - loss: 0.1432 - val_accuracy: 0.9496 - val_loss: 0.1619\n",
            "Epoch 23/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9631 - loss: 0.1269 - val_accuracy: 0.9580 - val_loss: 0.1570\n",
            "Epoch 24/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9599 - loss: 0.1231 - val_accuracy: 0.9580 - val_loss: 0.1457\n",
            "Epoch 25/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 0.9619 - loss: 0.1165 - val_accuracy: 0.9580 - val_loss: 0.1500\n",
            "Epoch 26/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 178ms/step - accuracy: 0.9700 - loss: 0.1123 - val_accuracy: 0.9664 - val_loss: 0.1360\n",
            "Epoch 27/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 191ms/step - accuracy: 0.9690 - loss: 0.1004 - val_accuracy: 0.9664 - val_loss: 0.1359\n",
            "Epoch 28/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 115ms/step - accuracy: 0.9718 - loss: 0.0923 - val_accuracy: 0.9664 - val_loss: 0.1286\n",
            "Epoch 29/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9706 - loss: 0.0893 - val_accuracy: 0.9664 - val_loss: 0.1331\n",
            "Epoch 30/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9762 - loss: 0.0894 - val_accuracy: 0.9664 - val_loss: 0.1166\n",
            "Epoch 31/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step - accuracy: 0.9654 - loss: 0.0859 - val_accuracy: 0.9664 - val_loss: 0.1354\n",
            "Epoch 32/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 110ms/step - accuracy: 0.9761 - loss: 0.0803 - val_accuracy: 0.9664 - val_loss: 0.1134\n",
            "Epoch 33/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.9685 - loss: 0.0784 - val_accuracy: 0.9664 - val_loss: 0.1187\n",
            "Epoch 34/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step - accuracy: 0.9794 - loss: 0.0700 - val_accuracy: 0.9664 - val_loss: 0.1152\n",
            "Epoch 35/35\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.9843 - loss: 0.0634 - val_accuracy: 0.9664 - val_loss: 0.1142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN model saved to disk.\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "CNN Accuracy: 94.96%\n",
            "\n",
            "CNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    OAF_Fear       1.00      1.00      1.00        45\n",
            "   OAF_angry       0.97      1.00      0.99        36\n",
            " OAF_disgust       0.00      0.00      0.00         5\n",
            "     YAF_sad       0.86      0.97      0.91        33\n",
            "\n",
            "    accuracy                           0.95       119\n",
            "   macro avg       0.71      0.74      0.73       119\n",
            "weighted avg       0.91      0.95      0.93       119\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 171ms/step\n",
            "RNN Accuracy: 96.64%\n",
            "\n",
            "RNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    OAF_Fear       1.00      0.98      0.99        45\n",
            "   OAF_angry       0.95      1.00      0.97        36\n",
            " OAF_disgust       1.00      0.60      0.75         5\n",
            "     YAF_sad       0.94      0.97      0.96        33\n",
            "\n",
            "    accuracy                           0.97       119\n",
            "   macro avg       0.97      0.89      0.92       119\n",
            "weighted avg       0.97      0.97      0.96       119\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib  # For saving and loading the label encoder\n",
        "import random\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Function to load and preprocess audio data\n",
        "def load_data(dataset_path):\n",
        "    features = []  # List to store feature vectors\n",
        "    labels = []    # List to store corresponding labels\n",
        "    for emotion in os.listdir(dataset_path):\n",
        "        emotion_path = os.path.join(dataset_path, emotion)\n",
        "        if os.path.isdir(emotion_path):\n",
        "            for file in os.listdir(emotion_path):\n",
        "                if file.endswith('.wav'):\n",
        "                    file_path = os.path.join(emotion_path, file)\n",
        "                    audio, sr = librosa.load(file_path, sr=None)  # Load audio file\n",
        "                    mfcc = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=30)  # Extract MFCC features\n",
        "                    mfcc_scaled = np.mean(mfcc.T, axis=0)  # Average MFCC coefficients\n",
        "                    features.append(mfcc_scaled)\n",
        "                    labels.append(emotion)\n",
        "    return np.array(features), np.array(labels)\n",
        "\n",
        "# Define the path to your dataset\n",
        "dataset_path = r'/content/drive/My Drive/FINAL_CODE_EMO_R_A ORIGINAL - Copy/DATASET/Tess'\n",
        "\n",
        "# Load the dataset\n",
        "X, y = load_data(dataset_path)\n",
        "\n",
        "# Encode the labels into numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the dataset into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=SEED\n",
        ")\n",
        "\n",
        "# Feature Standardization\n",
        "X_train = (X_train - np.mean(X_train, axis=0)) / np.std(X_train, axis=0)\n",
        "X_test = (X_test - np.mean(X_test, axis=0)) / np.std(X_test, axis=0)\n",
        "\n",
        "# Reshape the data for CNN and RNN\n",
        "X_train_rnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)  # For RNN\n",
        "X_test_rnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)      # For RNN\n",
        "X_train_cnn = X_train_rnn  # Same reshaping for CNN\n",
        "X_test_cnn = X_test_rnn\n",
        "\n",
        "# -------------------------- CNN Model -------------------------- #\n",
        "cnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=16, kernel_size=3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu',\n",
        "                           kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dropout(0.5),  # Moderate dropout\n",
        "    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile CNN Model\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train CNN Model\n",
        "cnn_model.fit(X_train_cnn, y_train, epochs=25, batch_size=32, validation_data=(X_test_cnn, y_test))\n",
        "\n",
        "# Save CNN Model\n",
        "cnn_model.save('emotion_detection_cnn_93.93.h5')\n",
        "print('CNN model saved to disk.')\n",
        "\n",
        "# -------------------------- RNN Model -------------------------- #\n",
        "rnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(X_train_rnn.shape[1], 1)),\n",
        "    tf.keras.layers.LSTM(128, return_sequences=False),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile RNN Model\n",
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train RNN Model\n",
        "rnn_model.fit(X_train_rnn, y_train, epochs=35, batch_size=64, validation_data=(X_test_rnn, y_test))\n",
        "\n",
        "# Save RNN Model\n",
        "rnn_model.save('emotion_detection_rnn_96.96.h5')\n",
        "print('RNN model saved to disk.')\n",
        "\n",
        "# -------------------------- Evaluate Models -------------------------- #\n",
        "\n",
        "# Evaluate CNN\n",
        "y_pred_cnn = np.argmax(cnn_model.predict(X_test_cnn), axis=1)\n",
        "cnn_accuracy = accuracy_score(y_test, y_pred_cnn)\n",
        "print(f'CNN Accuracy: {cnn_accuracy * 100:.2f}%')\n",
        "print(\"\\nCNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_cnn, target_names=label_encoder.classes_))\n",
        "\n",
        "# Evaluate RNN\n",
        "y_pred_rnn = np.argmax(rnn_model.predict(X_test_rnn), axis=1)\n",
        "rnn_accuracy = accuracy_score(y_test, y_pred_rnn)\n",
        "print(f'RNN Accuracy: {rnn_accuracy * 100:.2f}%')\n",
        "print(\"\\nRNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rnn, target_names=label_encoder.classes_))\n"
      ]
    }
  ]
}